{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78de6bbe-6379-4172-8dba-c2adf01fb348",
   "metadata": {},
   "source": [
    "===========================================================\n",
    "Manual Generalized Additive Model (GAM) Implementation\n",
    "-----------------------------------------------------------\n",
    "Author: Patrick Baghdasarian\n",
    "Date: 2025\n",
    "Description:\n",
    "    This script builds a GAM estimation framework from scratch.\n",
    "    It reads yield data from CSV files, computes descriptive\n",
    "    statistics, constructs spline bases, fits penalized IRLS\n",
    "    models, and visualizes results.\n",
    "\n",
    "Features:\n",
    "    - Reads multiple CSVs automatically.\n",
    "    - Computes dataset summaries and correlations.\n",
    "    - Supports multiple spline types:\n",
    "        * B-spline\n",
    "        * Natural cubic spline\n",
    "        * Thin-plate spline (approximate)\n",
    "        * Cubic regression spline\n",
    "    - Supports multiple link families:\n",
    "        * Gaussian (identity)\n",
    "        * Poisson (log)\n",
    "        * Binomial (logit)\n",
    "    - Implements full penalized IRLS estimation loop.\n",
    "    - Prints condition numbers for diagnostics.\n",
    "    - Plots fitted vs observed data.\n",
    "\n",
    "Dependencies:\n",
    "    numpy, pandas, matplotlib, scipy, patsy\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c124737-3785-47ca-8eb8-92faaf13236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "Manual Generalized Additive Model (GAM) Framework\n",
    "===========================================================\n",
    "Author: Patrick Baghdasarian\n",
    "Description:\n",
    "    - Loads yield data from CSV\n",
    "    - Builds spline basis manually and with Patsy\n",
    "    - Fits penalized GAMs (shared & by-Product smooths)\n",
    "    - Captures iterative matrices (W, X'WX, penalized)\n",
    "    - Generates PDF diagnostics\n",
    "    - Exposes all X, S, W matrices for later investigation\n",
    "===========================================================\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# Imports and Dependencies\n",
    "# ============================================================\n",
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import cond, LinAlgError\n",
    "from scipy.interpolate import BSpline\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Auto-install reportlab if not present\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
    "    from reportlab.lib.styles import getSampleStyleSheet\n",
    "except ImportError:\n",
    "    os.system('pip install reportlab')\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
    "    from reportlab.lib.styles import getSampleStyleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd3c32-c9d0-4af4-8efb-1ae1672588c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Load Data\n",
    "# ============================================================\n",
    "def load_yield_data(*filepaths):\n",
    "    dfs = []\n",
    "    for f in filepaths:\n",
    "        print(f\"\\nLoading {f} ...\")\n",
    "        df = pd.read_csv(f)\n",
    "        dfs.append(df)\n",
    "    data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    print(\"\\n‚úÖ Combined dataset shape:\", data.shape)\n",
    "    print(\"\\nüìã Columns:\", list(data.columns))\n",
    "    with pd.option_context(\"display.max_columns\", None):\n",
    "        print(\"\\nüìä Descriptive statistics:\\n\", data.describe(include='all'))\n",
    "\n",
    "    if {'Yield', 'Product'}.issubset(data.columns):\n",
    "        print(\"\\nüì¶ Mean Yield by Product:\\n\", data.groupby('Product', dropna=False)['Yield'].mean())\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06836a-9d30-43fa-a6f4-3ab9ade4ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Manual vs Patsy Spline Bases\n",
    "# ============================================================\n",
    "def manual_bspline_basis(x, n_knots=10, degree=3):\n",
    "    \"\"\"Manual open-uniform B-spline basis construction.\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    xmin, xmax = x.min(), x.max()\n",
    "    n_internal = n_knots - degree + 2\n",
    "    internal = np.linspace(xmin, xmax, n_internal)\n",
    "    knots = np.concatenate(([xmin]*degree, internal, [xmax]*degree))\n",
    "    n_basis = len(knots) - degree - 1\n",
    "    X = np.zeros((len(x), n_basis))\n",
    "    for i in range(n_basis):\n",
    "        c = np.zeros(n_basis)\n",
    "        c[i] = 1\n",
    "        spline = BSpline(knots, c, degree, extrapolate=False)\n",
    "        X[:, i] = spline(x)\n",
    "    return X, knots\n",
    "\n",
    "def second_diff_penalty(n_coef):\n",
    "    \"\"\"Discrete second-difference penalty matrix.\"\"\"\n",
    "    if n_coef < 3: return np.zeros((n_coef, n_coef))\n",
    "    D2 = np.diff(np.eye(n_coef), n=2, axis=0)\n",
    "    return D2.T @ D2\n",
    "\n",
    "def patsy_bspline_basis(x, df=10, degree=3, include_intercept=False):\n",
    "    \"\"\"Patsy spline basis construction.\"\"\"\n",
    "    X = np.asarray(dmatrix(\n",
    "    f\"0 + bs(x, df={df}, degree={degree}, include_intercept={str(include_intercept)})\",\n",
    "    {\"x\": x}, return_type='dataframe'\n",
    "    ))\n",
    "\n",
    "    S = second_diff_penalty(X.shape[1])\n",
    "    return X, S\n",
    "\n",
    "def plot_bases(x, X, title):\n",
    "    plt.figure(figsize=(9,5))\n",
    "    for j in range(X.shape[1]):\n",
    "        plt.plot(x, X[:,j], lw=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x\"); plt.ylabel(\"Basis value\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe54b2d-4026-4b83-9c94-244339bccd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. GLM Family Specifications\n",
    "# ============================================================\n",
    "def family_spec(family):\n",
    "    if family == \"gaussian\":\n",
    "        return {\"link\": lambda mu: mu, \"inv\": lambda eta: eta,\n",
    "                \"var\": lambda mu: np.ones_like(mu), \"gprime\": lambda mu: np.ones_like(mu),\n",
    "                \"mu_clip\": lambda mu: mu}\n",
    "    elif family == \"poisson\":\n",
    "        return {\"link\": np.log, \"inv\": np.exp,\n",
    "                \"var\": lambda mu: mu, \"gprime\": lambda mu: 1/np.maximum(mu,1e-12),\n",
    "                \"mu_clip\": lambda mu: np.maximum(mu,1e-12)}\n",
    "    elif family == \"binomial\":\n",
    "        inv = lambda eta: 1/(1+np.exp(-eta))\n",
    "        return {\"link\": lambda mu: np.log(mu/(1-mu)), \"inv\": inv,\n",
    "                \"var\": lambda mu: mu*(1-mu), \"gprime\": lambda mu: 1/np.maximum(mu*(1-mu),1e-12),\n",
    "                \"mu_clip\": lambda mu: np.clip(mu,1e-8,1-1e-8)}\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported family.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9b022-6b12-4990-831e-852976f823a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Penalized IRLS with Matrix Capture\n",
    "# ============================================================\n",
    "def penalized_irls(y, X, S, lam=10, family=\"gaussian\", max_iter=40, tol=1e-6,\n",
    "                   eps=1e-8, capture=True):\n",
    "    fam = family_spec(family)\n",
    "    n, p = X.shape\n",
    "    beta = np.zeros(p)\n",
    "    eta = X @ beta\n",
    "    mu = fam[\"inv\"](eta)\n",
    "    mu = fam[\"mu_clip\"](mu)\n",
    "\n",
    "    trace = {\"W\":[], \"XTWX\":[], \"Penalized\":[],\n",
    "             \"Cond_XWX\":[], \"Cond_S\":[], \"Cond_Penalized\":[], \"Beta\":[]}\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        gprime_mu = fam[\"gprime\"](mu)\n",
    "        var_mu = fam[\"var\"](mu)\n",
    "        z = eta + (y - mu) * gprime_mu\n",
    "        w_diag = 1.0 / np.maximum(var_mu * (gprime_mu**2), 1e-12)\n",
    "        W = np.diag(w_diag)\n",
    "\n",
    "        XTWX = X.T @ W @ X\n",
    "        Penalized = XTWX + lam*S + eps*np.eye(p)\n",
    "        cond_XWX, cond_S, cond_P = cond(XTWX), cond(S), cond(Penalized)\n",
    "        trace[\"Cond_XWX\"].append(cond_XWX)\n",
    "        trace[\"Cond_S\"].append(cond_S)\n",
    "        trace[\"Cond_Penalized\"].append(cond_P)\n",
    "        trace[\"W\"].append(W.copy())\n",
    "        trace[\"XTWX\"].append(XTWX.copy())\n",
    "        trace[\"Penalized\"].append(Penalized.copy())\n",
    "        trace[\"Beta\"].append(beta.copy())\n",
    "\n",
    "        b = X.T @ W @ z\n",
    "        try:\n",
    "            beta_new = np.linalg.solve(Penalized, b)\n",
    "        except LinAlgError:\n",
    "            beta_new = np.linalg.pinv(Penalized) @ b\n",
    "        delta = np.linalg.norm(beta_new - beta)\n",
    "        beta = beta_new\n",
    "        eta = X @ beta\n",
    "        mu = fam[\"inv\"](eta)\n",
    "        mu = fam[\"mu_clip\"](mu)\n",
    "        if delta < tol:\n",
    "            print(f\"Converged at iteration {it}\")\n",
    "            break\n",
    "    return beta, mu, np.diag(W), trace, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fdac4-4fd4-40a8-815a-5f04f180261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Combined GAM Fitting Routine\n",
    "# ============================================================\n",
    "def fit_gam(data, family=\"gaussian\", lam=100, df=10, degree=3):\n",
    "    x = data[\"Northing\"].values\n",
    "    y = data[\"Yield\"].values\n",
    "    print(f\"\\nBuilding both Manual and Patsy spline bases (df={df}, degree={degree})\")\n",
    "\n",
    "    # --- Build spline bases ---\n",
    "    # Manual B-spline\n",
    "    X_manual, knots_manual = manual_bspline_basis(x, n_knots=df, degree=degree)\n",
    "    S_manual = second_diff_penalty(X_manual.shape[1])\n",
    "\n",
    "    # Patsy B-spline\n",
    "    X_patsy, S_patsy = patsy_bspline_basis(x, df=df, degree=degree)\n",
    "\n",
    "    # --- Condition diagnostics ---\n",
    "    print(\"\\nCondition numbers:\")\n",
    "    print(f\" cond(X_manual) = {cond(X_manual):.3e}\")\n",
    "    print(f\" cond(X_patsy)  = {cond(X_patsy):.3e}\")\n",
    "\n",
    "    plot_bases(x, X_manual, \"Manual B-spline Basis Functions\")\n",
    "    plot_bases(x, X_patsy, \"Patsy B-spline Basis Functions\")\n",
    "\n",
    "    # ============================================================\n",
    "    # Fit both using IRLS (penalized least squares)\n",
    "    # ============================================================\n",
    "    print(\"\\n--- Fitting Manual Basis GAM ---\")\n",
    "    beta_m, mu_m, w_diag_m, trace_m, save_path_m = penalized_irls(\n",
    "        y, X_manual, S_manual, lam=lam, family=family\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Fitting Patsy Basis GAM ---\")\n",
    "    beta_p, mu_p, w_diag_p, trace_p, save_path_p = penalized_irls(\n",
    "        y, X_patsy, S_patsy, lam=lam, family=family\n",
    "    )\n",
    "\n",
    "    # ============================================================\n",
    "    # Visual comparison of smooth fits\n",
    "    # ============================================================\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.scatter(x, y, color='gray', s=20, label=\"Observed\")\n",
    "    plt.plot(x, mu_m, 'r', lw=2, label=\"Manual GAM fit\")\n",
    "    plt.plot(x, mu_p, 'b--', lw=2, label=\"Patsy GAM fit\")\n",
    "    plt.xlabel(\"Northing\"); plt.ylabel(\"Yield\")\n",
    "    plt.legend(); plt.title(\"Manual vs Patsy GAM Fits\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================\n",
    "    # Store all objects for later diagnostics and comparison\n",
    "    # ============================================================\n",
    "    gam_data = {\n",
    "        \"x\": x, \"y\": y,\n",
    "        \"X_manual\": X_manual, \"S_manual\": S_manual, \"knots_manual\": knots_manual,\n",
    "        \"X_patsy\": X_patsy, \"S_patsy\": S_patsy,\n",
    "        \"beta_manual\": beta_m, \"beta_patsy\": beta_p,\n",
    "        \"mu_manual\": mu_m, \"mu_patsy\": mu_p,\n",
    "        \"w_diag_manual\": w_diag_m, \"w_diag_patsy\": w_diag_p,\n",
    "        \"trace_manual\": trace_m, \"trace_patsy\": trace_p,\n",
    "        \"save_path_manual\": save_path_m, \"save_path_patsy\": save_path_p\n",
    "    }\n",
    "\n",
    "    print(\"‚úÖ Stored all matrices, weights, and fit results in `gam_data`.\")\n",
    "    return gam_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0983a-a391-4118-a010-639ea9b95271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. Utility: Condition Number Comparison\n",
    "# ============================================================\n",
    "def compare_condition_numbers(trace_m, trace_p):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(trace_m[\"Cond_Penalized\"], 'r', label=\"Manual\")\n",
    "    plt.plot(trace_p[\"Cond_Penalized\"], 'b', label=\"Patsy\")\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Iteration\"); plt.ylabel(\"Condition Number (log)\")\n",
    "    plt.legend(); plt.title(\"Condition Number Evolution\")\n",
    "    plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c7ca-7124-43de-9be6-cc06821bdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. Execution Example\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_yield_data(\"Example1SmoothHarvestStrip214.csv\")\n",
    "    gam_data = fit_gam(data, family=\"gaussian\", lam=100, df=10, degree=3)\n",
    "    compare_condition_numbers(gam_data[\"trace_manual\"], gam_data[\"trace_patsy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb304d-c6db-49a6-903b-7c8727ccda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Compatibility Helper for GCV module\n",
    "# ============================================================\n",
    "from patsy import dmatrix\n",
    "import numpy as np\n",
    "\n",
    "def build_spline_basis(x, spline_type=\"cr\", df=12, degree=3, include_intercept=False):\n",
    "    \"\"\"\n",
    "    Construct a spline basis and corresponding roughness penalty matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        The predictor variable (1D numeric array).\n",
    "    spline_type : {\"bs\", \"cr\"}\n",
    "        Type of spline basis:\n",
    "        - \"bs\": standard B-spline basis (raw B-splines)\n",
    "        - \"cr\": cubic regression spline (matches mgcv::s(bs=\"cr\"))\n",
    "    df : int\n",
    "        Degrees of freedom for spline basis.\n",
    "    degree : int\n",
    "        Degree of the spline (default 3 = cubic).\n",
    "    include_intercept : bool\n",
    "        Whether to include an intercept term in the basis.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray (n x k)\n",
    "        Design matrix for spline basis.\n",
    "    S : ndarray (k x k)\n",
    "        Penalty matrix approximating second derivative penalty.\n",
    "    spline_name : str\n",
    "        Label for the type of spline.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    # --- Select spline basis via Patsy ---\n",
    "    if spline_type == \"bs\":\n",
    "        # Capitalize Boolean explicitly to avoid \"name 'false' is not defined\"\n",
    "        include_str = \"True\" if include_intercept else \"False\"\n",
    "        X = np.asarray(\n",
    "            dmatrix(\n",
    "                f\"bs(x, df={df}, degree={degree}, include_intercept={include_str})\",\n",
    "                {\"x\": x},\n",
    "            )\n",
    "        )\n",
    "\n",
    "    elif spline_type == \"cr\":\n",
    "        # Cubic regression spline basis (mgcv equivalent)\n",
    "        X = np.asarray(dmatrix(f\"cr(x, df={df})\", {\"x\": x}))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"spline_type must be 'bs' or 'cr'.\")\n",
    "\n",
    "    # --- Build a simple roughness penalty (2nd-order finite difference) ---\n",
    "    k = X.shape[1]\n",
    "    D = np.diff(np.eye(k), n=2, axis=0)\n",
    "    S = D.T @ D\n",
    "\n",
    "    spline_name = f\"{spline_type}(df={df}, degree={degree})\"\n",
    "    return X, S, spline_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83f812-eff5-4600-aa6b-d3af9a596174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4C. Full-IRLS GCV (Gaussian / Poisson / Binomial)\n",
    "# ============================================================\n",
    "from numpy.linalg import solve, inv, LinAlgError\n",
    "\n",
    "def _glm_deviance(y, mu, family, eps=1e-12):\n",
    "    \"\"\"GLM deviance (up to additive constants) for scoring GCV across families.\"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    mu = np.asarray(mu, dtype=float)\n",
    "    mu = np.clip(mu, eps, 1 - eps) if family == \"binomial\" else np.maximum(mu, eps)\n",
    "\n",
    "    if family == \"gaussian\":\n",
    "        # Weighted RSS is handled by W; here deviance ~ unweighted RSS\n",
    "        return float(np.sum((y - mu)**2))\n",
    "\n",
    "    elif family == \"poisson\":\n",
    "        # 2 * sum( y log(y/mu) - (y - mu) ), with 0 log(0)=0 convention\n",
    "        term = np.zeros_like(y)\n",
    "        mask = y > 0\n",
    "        term[mask] = y[mask] * (np.log(y[mask] / mu[mask]))\n",
    "        return float(2.0 * np.sum(term - (y - mu)))\n",
    "\n",
    "    elif family == \"binomial\":\n",
    "        # Bernoulli deviance: 2 * sum( y log(y/mu) + (1-y) log((1-y)/(1-mu)) )\n",
    "        t1 = np.zeros_like(y)\n",
    "        t2 = np.zeros_like(y)\n",
    "        mask1 = (y > 0)\n",
    "        mask2 = (y < 1)\n",
    "        t1[mask1] = y[mask1] * np.log(y[mask1] / mu[mask1])\n",
    "        t2[mask2] = (1 - y[mask2]) * np.log((1 - y[mask2]) / (1 - mu[mask2]))\n",
    "        return float(2.0 * np.sum(t1 + t2))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported family for deviance.\")\n",
    "\n",
    "def _trace_hat_edf(X, w_diag, S, lam, eps=1e-8):\n",
    "    \"\"\"\n",
    "    edf = tr( (X' W X) (X' W X + lam S + eps I)^{-1} )\n",
    "    Avoids forming n√ón hat matrix; uses p√óp solve.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    w_diag = np.asarray(w_diag, dtype=float)\n",
    "    S = np.asarray(S, dtype=float)\n",
    "    p = X.shape[1]\n",
    "    XtWX = X.T @ (w_diag[:, None] * X)\n",
    "    P = XtWX + lam * S + eps * np.eye(p)\n",
    "\n",
    "    try:\n",
    "        # Solve P^{-1} XtWX via linear solves (more stable than explicit inverse)\n",
    "        C = solve(P, XtWX)\n",
    "    except LinAlgError:\n",
    "        C = np.linalg.pinv(P) @ XtWX\n",
    "\n",
    "    return float(np.trace(C)), XtWX, P\n",
    "\n",
    "def select_lambda_gcv_glm(\n",
    "    y, X, S, family=\"gaussian\",\n",
    "    lam_grid=None, max_iter=50, tol=1e-6, eps=1e-8, verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Full IRLS per-Œª, then GCV score with GLM deviance and edf = tr(H).\n",
    "\n",
    "    GCV(Œª) = D(Œª) / (n - edf(Œª))^2      (common working form)\n",
    "    For Gaussian, D reduces to RSS; for Poisson/Binomial it is GLM deviance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lam_opt, gcv_scores, lam_grid, records\n",
    "      where records[i] = dict(lam, dev, edf, trA, condP, beta, mu)\n",
    "    \"\"\"\n",
    "    if lam_grid is None:\n",
    "        lam_grid = np.logspace(-4, 6, 35)\n",
    "\n",
    "    n = len(y)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    records = []\n",
    "    gcv_scores = []\n",
    "\n",
    "    # Warm-start across the grid\n",
    "    beta0 = None\n",
    "\n",
    "    for lam in lam_grid:\n",
    "        # Run IRLS at this lambda\n",
    "        # (Warm-start by injecting beta0 if you extend penalized_irls to accept it)\n",
    "        beta, mu, w_diag, trace, _ = penalized_irls(\n",
    "        y=y, X=X, S=S, lam=lam, family=family,\n",
    "        max_iter=max_iter, tol=tol, eps=eps,\n",
    "        capture=False  # speed\n",
    "        )\n",
    "\n",
    "        beta0 = beta  # keep for potential future extension\n",
    "\n",
    "        # Effective df via tr( XtWX * P^{-1} )\n",
    "        edf, XtWX, P = _trace_hat_edf(X, w_diag, S, lam, eps=eps)\n",
    "\n",
    "        # Deviance (family-appropriate)\n",
    "        dev = _glm_deviance(y, mu, family)\n",
    "\n",
    "        # GCV score\n",
    "        denom = (n - edf)\n",
    "        gcv = float(dev / (denom**2 + eps))\n",
    "\n",
    "        # Condition number of penalized system\n",
    "        try:\n",
    "            condP = float(cond(P))\n",
    "        except LinAlgError:\n",
    "            condP = np.inf\n",
    "\n",
    "        records.append({\n",
    "            \"lam\": float(lam),\n",
    "            \"dev\": float(dev),\n",
    "            \"edf\": float(edf),\n",
    "            \"gcv\": float(gcv),\n",
    "            \"condP\": condP,\n",
    "            \"beta\": beta.copy(),\n",
    "            \"mu\": mu.copy(),\n",
    "        })\n",
    "        gcv_scores.append(gcv)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Œª={lam:9.3e}  GCV={gcv:12.5f}  dev={dev:12.5f}  \"\n",
    "                  f\"edf={edf:8.3f}  cond(P)={condP:9.3e}\")\n",
    "\n",
    "    idx = int(np.argmin(gcv_scores))\n",
    "    lam_opt = float(lam_grid[idx])\n",
    "    if verbose:\n",
    "        print(f\"\\n‚úÖ Optimal Œª (full-IRLS GCV) = {lam_opt:.3e}\")\n",
    "    return lam_opt, gcv_scores, lam_grid, records\n",
    "\n",
    "def fit_gam_with_gcv_glm(\n",
    "    data, spline_type=\"bs\", family=\"gaussian\", df=12, degree=3,\n",
    "    lam_grid=None, max_iter=50, tol=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    Build basis + penalty (with unpenalized intercept), select Œª via full-IRLS GCV,\n",
    "    then refit once at Œª* to return final (beta, mu, trace, lam_opt).\n",
    "    \"\"\"\n",
    "    x = data[\"Northing\"].values.astype(float)\n",
    "    y = data[\"Yield\"].values.astype(float)\n",
    "\n",
    "    # Build spline basis using your existing helper\n",
    "    X_smooth, S, spline_name = build_spline_basis(x, spline_type=spline_type, df=df, degree=degree)\n",
    "    n = len(y)\n",
    "    intercept = np.ones((n, 1))\n",
    "    X = np.hstack([intercept, X_smooth])\n",
    "    S = np.block([\n",
    "        [np.zeros((1,1)),                np.zeros((1, S.shape[1]))],\n",
    "        [np.zeros((S.shape[0], 1)),      S]\n",
    "    ])\n",
    "\n",
    "    lam_opt, gcv_scores, lam_grid, records = select_lambda_gcv_glm(\n",
    "        y, X, S, family=family, lam_grid=lam_grid, max_iter=max_iter, tol=tol, verbose=True\n",
    "    )\n",
    "\n",
    "    # Final refit at Œª*\n",
    "    beta, mu, w_diag, trace, save_path = penalized_irls(\n",
    "        y=y, X=X, S=S, lam=lam_opt, family=family,\n",
    "        max_iter=max_iter, tol=tol, capture=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"x\": x, \"y\": y, \"X\": X, \"S\": S, \"spline_name\": spline_name,\n",
    "        \"beta\": beta, \"mu\": mu, \"trace\": trace, \"w_diag\": w_diag,\n",
    "        \"lam_opt\": lam_opt, \"gcv_scores\": gcv_scores, \"lam_grid\": lam_grid,\n",
    "        \"gcv_records\": records\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb99c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_yield_data(\"Example1SmoothHarvestStrip214.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d89c00-1e58-411e-90ce-45ef08d2c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_yield_data(\"Example1SmoothHarvestStrip218.csv\")\n",
    "\n",
    "res = fit_gam_with_gcv_glm(\n",
    "    data,\n",
    "    spline_type=\"bs\",       # or \"manual\"\n",
    "    family=\"gaussian\",      # \"poisson\" or \"binomial\" also supported\n",
    "    df=12, degree=3,\n",
    "    lam_grid=np.logspace(-4, 6, 35)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c608a-b76f-44a0-9c99-a3416cc6b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Auto-select Œª with full-IRLS GCV and refit once at Œª*\n",
    "res = fit_gam_with_gcv_glm(\n",
    "    data,\n",
    "    spline_type=\"bs\",        # or \"cr\"\n",
    "    family=\"gaussian\",        # \"gaussian\", \"poisson\", \"binomial\"\n",
    "    df=12, degree=3,\n",
    "    lam_grid=np.logspace(-4, 6, 35)\n",
    ")\n",
    "\n",
    "# 2) Inspect the chosen Œª and edf progression\n",
    "print(\"Œª* =\", res[\"lam_opt\"])\n",
    "plt.semilogx(res[\"lam_grid\"], res[\"gcv_scores\"], 'o-')\n",
    "plt.xlabel(\"Œª\"); plt.ylabel(\"GCV\"); plt.title(\"Full-IRLS GCV\"); plt.show()\n",
    "\n",
    "# 3) Compare to mgcv (if you've exported gam_compare.csv and generated mgcv_yhat.csv)\n",
    "#    (See earlier steps in our thread for the mgcv/R workflow.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68174c6d-d9ac-4611-aabb-ed5080a015a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Comparisons: pyGAM\n",
    "# =========================\n",
    "def compare_with_pygam(x, y, lam=100.0, family=\"gaussian\", spline_terms=10, plot=True):\n",
    "    \"\"\"\n",
    "    Fit a comparable GAM with pyGAM and compare fitted values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pygam\n",
    "    except ImportError:\n",
    "        os.system('pip install pygam')\n",
    "        import pygam\n",
    "\n",
    "    # family mapping\n",
    "    fam_map = {\n",
    "        \"gaussian\": pygam.GammaDist() if False else pygam.LinearGAM,  # use LinearGAM for Gaussian\n",
    "        \"poisson\": pygam.PoissonGAM,\n",
    "        \"binomial\": pygam.LogisticGAM\n",
    "    }\n",
    "    if family not in fam_map:\n",
    "        raise ValueError(\"Unsupported family for pyGAM comparison.\")\n",
    "\n",
    "    # Build model\n",
    "    if family == \"gaussian\":\n",
    "        gam = pygam.LinearGAM(pygam.s(0, n_splines=spline_terms)).fit(x.reshape(-1,1), y)\n",
    "    elif family == \"poisson\":\n",
    "        gam = pygam.PoissonGAM(pygam.s(0, n_splines=spline_terms)).fit(x.reshape(-1,1), y)\n",
    "    else:\n",
    "        gam = pygam.LogisticGAM(pygam.s(0, n_splines=spline_terms)).fit(x.reshape(-1,1), y)\n",
    "\n",
    "    yhat = gam.predict(x.reshape(-1,1))\n",
    "    rmse = float(np.sqrt(np.mean((y - yhat)**2)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(9,5))\n",
    "        plt.scatter(x, y, s=20, color=\"gray\", label=\"Observed\")\n",
    "        plt.plot(x, yhat, \"k--\", lw=2, label=\"pyGAM fit\")\n",
    "        plt.title(\"pyGAM comparison\")\n",
    "        plt.legend(); plt.grid(True); plt.show()\n",
    "    return {\"pygam_rmse\": rmse, \"pygam_fitted\": yhat, \"pygam_model\": gam}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4a197-7835-4386-bf9f-86626a24bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Comparisons: R mgcv via rpy2\n",
    "# =========================\n",
    "def compare_with_mgcv_via_rpy2(x, y, k=10, family=\"gaussian\", plot=True):\n",
    "    \"\"\"\n",
    "    Requires: R installed, mgcv installed in R, and rpy2 in Python.\n",
    "    Formula: y ~ s(x, k=k, bs='cr')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import rpy2.robjects as ro\n",
    "        from rpy2.robjects import numpy2ri\n",
    "        numpy2ri.activate()\n",
    "    except Exception as e:\n",
    "        print(\"rpy2 is not available or R not installed. Falling back to CSV handoff.\")\n",
    "        return None\n",
    "\n",
    "    ro.r(\"suppressPackageStartupMessages(library(mgcv))\")\n",
    "    r = ro.r\n",
    "\n",
    "    r.assign(\"x\", np.asarray(x))\n",
    "    r.assign(\"y\", np.asarray(y))\n",
    "    r.assign(\"kval\", int(k))\n",
    "\n",
    "    if family == \"gaussian\":\n",
    "        fam = \"gaussian\"\n",
    "    elif family == \"poisson\":\n",
    "        fam = \"poisson\"\n",
    "    elif family == \"binomial\":\n",
    "        fam = \"binomial\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported family for mgcv.\")\n",
    "\n",
    "    r(f\"\"\"\n",
    "        fit <- gam(y ~ s(x, k=kval, bs='cr'), family={fam}())\n",
    "        yhat <- fitted(fit)\n",
    "    \"\"\")\n",
    "    yhat = np.array(r(\"yhat\"))\n",
    "    rmse = float(np.sqrt(np.mean((y - yhat)**2)))\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(9,5))\n",
    "        plt.scatter(x, y, s=20, color=\"gray\", label=\"Observed\")\n",
    "        plt.plot(x, yhat, \"g\", lw=2, label=\"mgcv fit (R)\")\n",
    "        plt.title(\"mgcv (R) comparison\")\n",
    "        plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    return {\"mgcv_rmse\": rmse, \"mgcv_fitted\": yhat}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440706f-8ded-48dc-8186-9fdef64ecc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export your data to CSV for R mgcv comparison\n",
    "pd.DataFrame({\"x\": gam_data[\"x\"], \"y\": gam_data[\"y\"]}).to_csv(\"gam_compare.csv\", index=False)\n",
    "print(\"Saved gam_compare.csv for mgcv verification.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588b1c9-1d79-4152-8975-2456f67ec38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "yhat_mgcv = pd.read_csv(\"mgcv_yhat.csv\")[\"yhat\"].to_numpy()\n",
    "rmse_mgcv = np.sqrt(np.mean((gam_data[\"y\"] - yhat_mgcv)**2))\n",
    "print(f\"mgcv RMSE vs Manual/Patsy GAM: {rmse_mgcv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e661ae-f08d-4209-a7f0-a5199572f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin install rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c191d2a-7a60-4561-bdfa-65e76711ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rpy2.robjects import r\n",
    "\n",
    "# # Try loading mgcv\n",
    "# r('library(mgcv)')\n",
    "\n",
    "# # Check its version (optional)\n",
    "# r('print(packageVersion(\"mgcv\"))')\n",
    "\n",
    "# # If it's not installed yet, run this ONCE:\n",
    "# r('install.packages(\"mgcv\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bbd70-9bf5-40c7-a382-8c106e77650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpy2\n",
    "# print(\"rpy2 version:\", rpy2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9938b6-7dfa-40e6-9c9b-f1d5d2645c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib.metadata\n",
    "# print(importlib.metadata.version(\"rpy2\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a7bb1-257c-4c82-851c-ba61a317549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rpy2.robjects import r\n",
    "# print(\"R version:\", r(\"R.version.string\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea4768-fe60-46cc-a22a-3cbcc5249396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"R_HOME\"] = \"C:\\\\Program Files\\\\R\\\\R-4.5.1\"\n",
    "# compare_with_mgcv_via_rpy2(res[\"x\"], res[\"y\"], k=12, family=\"gaussian\", plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d783f-0f32-456d-b980-ead5b017d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_mgcv_via_rpy2(x, y, k=10, family=\"gaussian\", plot=True):\n",
    "    \"\"\"\n",
    "    Direct Python‚ÜîR mgcv comparison using updated rpy2 API (>=3.5).\n",
    "    Compatible with R 4.5+ and rpy2 3.6+.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "\n",
    "    # --- R environment paths ---\n",
    "    os.environ[\"R_HOME\"] = r\"C:\\Program Files\\R\\R-4.5.1\"\n",
    "    os.environ[\"R_USER\"] = os.getenv(\"USERPROFILE\", \"\")\n",
    "\n",
    "    print(\"üîç Checking R and mgcv connectivity...\")\n",
    "\n",
    "    try:\n",
    "        import rpy2.robjects as ro\n",
    "        from rpy2.robjects import conversion, default_converter, numpy2ri\n",
    "        from contextlib import contextmanager\n",
    "\n",
    "        # --- Context-aware conversion ---\n",
    "        @contextmanager\n",
    "        def rpy2_numpy_context():\n",
    "            with conversion.localconverter(\n",
    "                default_converter + numpy2ri.converter\n",
    "            ):\n",
    "                yield\n",
    "\n",
    "        r = ro.r\n",
    "        with rpy2_numpy_context():\n",
    "            # Load mgcv\n",
    "            r('suppressPackageStartupMessages(library(mgcv))')\n",
    "            r('cat(\"‚úÖ mgcv loaded successfully in R.\\\\n\")')\n",
    "\n",
    "            # Send data\n",
    "            r.assign(\"x\", np.asarray(x))\n",
    "            r.assign(\"y\", np.asarray(y))\n",
    "            r.assign(\"kval\", int(k))\n",
    "\n",
    "            # Choose family\n",
    "            if family == \"gaussian\":\n",
    "                fam = \"gaussian\"\n",
    "            elif family == \"poisson\":\n",
    "                fam = \"poisson\"\n",
    "            elif family == \"binomial\":\n",
    "                fam = \"binomial\"\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported family for mgcv.\")\n",
    "\n",
    "            print(\"‚öôÔ∏è  Running mgcv::gam(y ~ s(x, k=kval, bs='cr')) ...\")\n",
    "            r(f\"\"\"\n",
    "                fit <- gam(y ~ s(x, k=kval, bs='cr'), family={fam}())\n",
    "                yhat <- fitted(fit)\n",
    "                cat(\"Effective degrees of freedom:\", sum(fit$edf), \"\\\\n\")\n",
    "            \"\"\")\n",
    "            yhat = np.array(r(\"yhat\"))\n",
    "            rmse = float(np.sqrt(np.mean((y - yhat)**2)))\n",
    "\n",
    "        # --- Plot results ---\n",
    "        if plot:\n",
    "            plt.figure(figsize=(9,5))\n",
    "            plt.scatter(x, y, s=20, color=\"gray\", label=\"Observed\")\n",
    "            plt.plot(x, yhat, \"g\", lw=2, label=\"mgcv fit (R)\")\n",
    "            plt.title(\"mgcv (R) comparison via rpy2 (updated API)\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"‚úÖ mgcv RMSE vs observed: {rmse:.4f}\")\n",
    "        return {\"mgcv_rmse\": rmse, \"mgcv_fitted\": yhat}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå rpy2 failed to initialize R interface.\")\n",
    "        print(\"Error:\", e)\n",
    "        print(\"Falling back to CSV handoff for mgcv.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8571f-e5de-4618-a3fd-9a8a95e6ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_with_mgcv_via_rpy2(\n",
    "#     res[\"x\"],\n",
    "#     res[\"y\"],\n",
    "#     k=12,\n",
    "#     family=\"gaussian\",\n",
    "#     plot=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528bafe-1e51-4726-ae99-6d457f34574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "print(\"rpy2 version:\", importlib.metadata.version(\"rpy2\"))\n",
    "\n",
    "from rpy2.robjects import r\n",
    "print(\"R version:\", r(\"R.version.string\")[0])\n",
    "\n",
    "\n",
    "# 2. Set environment (only needed once)\n",
    "import os\n",
    "os.environ[\"R_HOME\"] = r\"C:\\Program Files\\R\\R-4.5.1\"\n",
    "\n",
    "# 3. Run your GAM comparison\n",
    "res_mgcv = compare_with_mgcv_via_rpy2(\n",
    "    res[\"x\"],\n",
    "    res[\"y\"],\n",
    "    k=12,\n",
    "    family=\"gaussian\",\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53217d30-aa41-4264-9914-207822978e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "print(\"rpy2 version:\", importlib.metadata.version(\"rpy2\"))\n",
    "\n",
    "from rpy2.robjects import r\n",
    "print(\"R version:\", r(\"R.version.string\")[0])\n",
    "\n",
    "import os\n",
    "os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\\\R\\\\R-4.5.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8ef36-12fd-4566-8492-48fb960df47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: reuse your existing fit\n",
    "res = fit_gam_with_gcv_glm(\n",
    "    data,\n",
    "    spline_type=\"bs\",\n",
    "    family=\"gaussian\",\n",
    "    df=12, degree=3,\n",
    "    lam_grid=np.logspace(-4, 6, 35)\n",
    ")\n",
    "print(\"Œª* =\", res[\"lam_opt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b53f1a-6055-4617-944b-eea4b246793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_mgcv_via_rpy2(x, y, k=12, family=\"gaussian\", plot=True):\n",
    "    \"\"\"\n",
    "    Compare Python penalized-IRLS GAM vs R mgcv::gam via rpy2.\n",
    "    Exports mgcv_yhat.csv and returns both fits + RMSE.\n",
    "    \"\"\"\n",
    "    import numpy as np, matplotlib.pyplot as plt, pandas as pd, os\n",
    "    os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\\\R\\\\R-4.5.1\"\n",
    "    os.environ[\"R_USER\"] = os.getenv(\"USERPROFILE\", \"\")\n",
    "\n",
    "    print(\"üîç Checking R and mgcv connectivity...\")\n",
    "\n",
    "    try:\n",
    "        import rpy2.robjects as ro\n",
    "        from rpy2.robjects import conversion, default_converter, numpy2ri\n",
    "        from contextlib import contextmanager\n",
    "\n",
    "        @contextmanager\n",
    "        def rpy2_numpy_context():\n",
    "            with conversion.localconverter(default_converter + numpy2ri.converter):\n",
    "                yield\n",
    "\n",
    "        r = ro.r\n",
    "        with rpy2_numpy_context():\n",
    "            r('suppressPackageStartupMessages(library(mgcv))')\n",
    "            r('cat(\"‚úÖ mgcv loaded successfully in R.\\\\n\")')\n",
    "\n",
    "            r.assign(\"x\", np.asarray(x))\n",
    "            r.assign(\"y\", np.asarray(y))\n",
    "            r.assign(\"kval\", int(k))\n",
    "\n",
    "            if family not in [\"gaussian\", \"poisson\", \"binomial\"]:\n",
    "                raise ValueError(\"Unsupported family for mgcv.\")\n",
    "\n",
    "            print(f\"‚öôÔ∏è  Running mgcv::gam(y ~ s(x, k={k}, bs='cr'), family={family}) ...\")\n",
    "            r(f\"\"\"\n",
    "                fit <- gam(y ~ s(x, k=kval, bs='cr'), family={family}())\n",
    "                yhat <- fitted(fit)\n",
    "                cat(sum(fit$edf), \"degrees of freedom\\\\n\")\n",
    "            \"\"\")\n",
    "            yhat = np.array(r(\"yhat\"))\n",
    "            rmse = float(np.sqrt(np.mean((y - yhat)**2)))\n",
    "            pd.DataFrame({\"x\": x, \"yhat_mgcv\": yhat}).to_csv(\"mgcv_yhat.csv\", index=False)\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(9,5))\n",
    "            plt.scatter(x, y, s=20, color=\"gray\", label=\"Observed\")\n",
    "            plt.plot(x, yhat, \"g\", lw=2, label=\"mgcv fit (R)\")\n",
    "            plt.title(\"R mgcv fit via rpy2 (updated API)\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"‚úÖ mgcv RMSE vs observed: {rmse:.4f}\")\n",
    "        return {\"mgcv_rmse\": rmse, \"mgcv_fitted\": yhat}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå rpy2 failed to initialize R interface.\")\n",
    "        print(\"Error:\", e)\n",
    "        print(\"Falling back to CSV handoff for mgcv.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779466a-f862-4b16-b784-51e4d6af2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgcv_res = compare_with_mgcv_via_rpy2(\n",
    "    res[\"x\"],\n",
    "    res[\"y\"],\n",
    "    k=12,\n",
    "    family=\"gaussian\",\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a25cf-8b66-4ac0-9560-6f49ae1e17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reload R results\n",
    "mgcv_df = pd.read_csv(\"mgcv_yhat.csv\")\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.scatter(res[\"x\"], res[\"y\"], s=20, color=\"gray\", label=\"Observed\")\n",
    "plt.plot(res[\"x\"], res[\"mu\"], \"r--\", lw=2, label=\"Python IRLS GAM\")\n",
    "plt.plot(mgcv_df[\"x\"], mgcv_df[\"yhat_mgcv\"], \"g\", lw=2, label=\"R mgcv GAM\")\n",
    "plt.title(\"Python GAM vs R mgcv Comparison\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "rmse_py = np.sqrt(np.mean((res[\"y\"] - res[\"mu\"])**2))\n",
    "rmse_r = np.sqrt(np.mean((res[\"y\"] - mgcv_df[\"yhat_mgcv\"])**2))\n",
    "print(f\"Python GAM RMSE: {rmse_py:.4f} | R mgcv RMSE: {rmse_r:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2776d7b-70cf-4c18-aa85-1521a2491d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load mgcv fit ---\n",
    "mgcv_df = pd.read_csv(\"mgcv_yhat.csv\")\n",
    "\n",
    "# --- Compute fits and residuals ---\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"x\": res[\"x\"],\n",
    "    \"y_observed\": res[\"y\"],\n",
    "    \"y_python_fit\": res[\"mu\"],\n",
    "    \"y_mgcv_fit\": mgcv_df[\"yhat_mgcv\"],\n",
    "})\n",
    "\n",
    "# Residual diagnostics\n",
    "comparison_df[\"residual_python\"] = comparison_df[\"y_observed\"] - comparison_df[\"y_python_fit\"]\n",
    "comparison_df[\"residual_mgcv\"] = comparison_df[\"y_observed\"] - comparison_df[\"y_mgcv_fit\"]\n",
    "\n",
    "# --- RMSE ---\n",
    "rmse_python = np.sqrt(np.mean(comparison_df[\"residual_python\"] ** 2))\n",
    "rmse_mgcv = np.sqrt(np.mean(comparison_df[\"residual_mgcv\"] ** 2))\n",
    "\n",
    "# --- Export ---\n",
    "comparison_df.to_csv(\"gam_python_vs_mgcv_comparison.csv\", index=False)\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.scatter(comparison_df[\"x\"], comparison_df[\"y_observed\"], s=25, color=\"gray\", label=\"Observed\")\n",
    "plt.plot(comparison_df[\"x\"], comparison_df[\"y_python_fit\"], \"r--\", lw=2, label=\"Python IRLS GAM\")\n",
    "plt.plot(comparison_df[\"x\"], comparison_df[\"y_mgcv_fit\"], \"g\", lw=2, label=\"R mgcv GAM\")\n",
    "plt.title(\"Python GAM vs R mgcv (Fitted Curves)\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Residual Plot ---\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.scatter(comparison_df[\"x\"], comparison_df[\"residual_python\"], color=\"red\", alpha=0.6, label=\"Python residuals\")\n",
    "plt.scatter(comparison_df[\"x\"], comparison_df[\"residual_mgcv\"], color=\"green\", alpha=0.6, label=\"R mgcv residuals\")\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.title(\"Residuals Comparison (Python vs mgcv)\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"Residual\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Summary output ---\n",
    "summary = pd.DataFrame({\n",
    "    \"Model\": [\"Python GAM (IRLS)\", \"R mgcv\"],\n",
    "    \"RMSE\": [rmse_python, rmse_mgcv],\n",
    "    \"Mean Residual\": [comparison_df[\"residual_python\"].mean(), comparison_df[\"residual_mgcv\"].mean()],\n",
    "    \"Std Residual\": [comparison_df[\"residual_python\"].std(), comparison_df[\"residual_mgcv\"].std()],\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Model Performance Comparison:\")\n",
    "display(summary)\n",
    "print(\"\\nüìÅ Saved: gam_python_vs_mgcv_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1335b3f-144c-450b-84d5-2b96b13e1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Example: load your predictor variable (replace this with your actual data column)\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"Example1SmoothHarvestStrip214.csv\")\n",
    "\n",
    "# Suppose your predictor is called 'Northing' or similar:\n",
    "x = data[\"Northing\"].values  # or whatever column name you used\n",
    "\n",
    "# Now construct the spline basis with df=12 and cubic degree\n",
    "X = np.asarray(\n",
    "    dmatrix(\"bs(x, df=12, degree=3, include_intercept=False)\", {\"x\": x})\n",
    ")\n",
    "\n",
    "print(\"Design matrix shape:\", X.shape)\n",
    "print(X[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305689d-803e-49f9-b779-e294d3ef714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import r, conversion, default_converter\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import numpy2ri\n",
    "import numpy as np\n",
    "\n",
    "# Example numeric vector\n",
    "x = np.linspace(0, 1, 50)\n",
    "k = 12\n",
    "\n",
    "# --- Load R mgcv ---\n",
    "r('suppressPackageStartupMessages(library(mgcv))')\n",
    "\n",
    "# --- Explicitly convert numpy arrays to R vectors ---\n",
    "x_r = numpy2ri.py2rpy(x)\n",
    "r.assign(\"x\", x_r)\n",
    "r.assign(\"kval\", k)\n",
    "\n",
    "# --- Conversion context for pulling back arrays ---\n",
    "with localconverter(default_converter + numpy2ri.converter):\n",
    "    r('B <- smoothCon(s(x, k=kval, bs=\"cr\"), data=data.frame(x=x))[[1]]$X')\n",
    "    r('S <- smoothCon(s(x, k=kval, bs=\"cr\"), data=data.frame(x=x))[[1]]$S[[1]]')\n",
    "    X_mgcv = np.array(r('B'))\n",
    "    S_mgcv = np.array(r('S'))\n",
    "\n",
    "print(\"Design matrix shape:\", X_mgcv.shape)\n",
    "print(\"Penalty matrix shape:\", S_mgcv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37fb8c-96ad-4ea1-9bc5-cf7ac2176d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mgcv_basis(x, k=12, bs=\"cr\"):\n",
    "    from rpy2.robjects import r, conversion, default_converter\n",
    "    from rpy2.robjects.conversion import localconverter\n",
    "    from rpy2.robjects import numpy2ri\n",
    "    import numpy as np\n",
    "\n",
    "    r('suppressPackageStartupMessages(library(mgcv))')\n",
    "    x_r = numpy2ri.py2rpy(np.asarray(x))\n",
    "    r.assign(\"x\", x_r)\n",
    "    r.assign(\"kval\", k)\n",
    "    r.assign(\"bs_type\", bs)\n",
    "\n",
    "    with localconverter(default_converter + numpy2ri.converter):\n",
    "        r('B <- smoothCon(s(x, k=kval, bs=bs_type), data=data.frame(x=x))[[1]]$X')\n",
    "        r('S <- smoothCon(s(x, k=kval, bs=bs_type), data=data.frame(x=x))[[1]]$S[[1]]')\n",
    "        X_mgcv = np.array(r('B'))\n",
    "        S_mgcv = np.array(r('S'))\n",
    "    return X_mgcv, S_mgcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43731974-edd9-458c-b911-722f803b0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mgcv, S_mgcv = extract_mgcv_basis(x, k=12)\n",
    "print(\"Design matrix shape:\", X_mgcv.shape)\n",
    "print(\"Penalty matrix shape:\", S_mgcv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200ed64-5cae-4e44-82e4-6ecc448c30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "import numpy as np\n",
    "\n",
    "# --- Python cubic regression spline basis (same as mgcv bs=\"cr\") ---\n",
    "X_py = np.asarray(dmatrix(\"cr(x, df=12)\", {\"x\": x}))\n",
    "X_py = X_py[:, 1:]  # drop intercept column\n",
    "print(\"Python design matrix:\", X_py.shape)\n",
    "\n",
    "# --- Normalize both bases for scale-invariant comparison ---\n",
    "def normalize(M):\n",
    "    return M / np.linalg.norm(M, axis=0, keepdims=True)\n",
    "\n",
    "X_diff = np.linalg.norm(normalize(X_py) - normalize(X_mgcv))\n",
    "print(f\"‚ÄñNormalized difference between Python and mgcv bases‚Äñ = {X_diff:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fee5e-c3a1-46c5-814e-1b7b0838ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import solve, LinAlgError\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def fit_fixed_lambda(\n",
    "    x, y, lam, family=\"gaussian\", df=12, degree=3, spline_type=\"cr\",\n",
    "    eps=1e-8, max_iter=50, tol=1e-6, return_internals=False\n",
    "):\n",
    "    # Build basis with unpenalized intercept (first column)\n",
    "    X_smooth, S, _ = build_spline_basis(x, spline_type=spline_type, df=df, degree=degree)\n",
    "    n = len(y)\n",
    "    X = np.hstack([np.ones((n,1)), X_smooth])\n",
    "    S = np.block([[np.zeros((1,1)),                 np.zeros((1, S.shape[1]))],\n",
    "                  [np.zeros((S.shape[0],1)),       S]])\n",
    "\n",
    "    beta, mu, w_diag, trace, _ = penalized_irls(\n",
    "        y=y, X=X, S=S, lam=lam, family=family, max_iter=max_iter, tol=tol, eps=eps, capture=True\n",
    "    )\n",
    "\n",
    "    # algebraic checks\n",
    "    XtWX = X.T @ (w_diag[:,None]*X)\n",
    "    P = XtWX + lam*S + eps*np.eye(X.shape[1])\n",
    "    z = (X @ beta) + (y - mu) * family_spec(family)[\"gprime\"](mu)\n",
    "    rhs = X.T @ (w_diag[:,None]*z)\n",
    "    try:\n",
    "        res = P @ beta - rhs\n",
    "        normal_eq_relres = np.linalg.norm(res) / max(np.linalg.norm(rhs), eps)\n",
    "    except Exception:\n",
    "        normal_eq_relres = np.nan\n",
    "\n",
    "    # edf\n",
    "    try:\n",
    "        C = solve(P, XtWX)\n",
    "    except LinAlgError:\n",
    "        C = np.linalg.pinv(P) @ XtWX\n",
    "    edf = float(np.trace(C))\n",
    "\n",
    "    out = {\"beta\": beta, \"mu\": mu, \"edf\": edf, \"w_diag\": w_diag,\n",
    "           \"normal_eq_relres\": normal_eq_relres, \"X\": X, \"S\": S}\n",
    "    return (out if return_internals else mu)\n",
    "\n",
    "def kfold_cv_fixed_lambda(\n",
    "    x, y, lam, family=\"gaussian\", df=12, degree=3, spline_type=\"cr\",\n",
    "    K=5, shuffle=True, seed=1, metric=\"rmse\"\n",
    "):\n",
    "    kf = KFold(n_splits=K, shuffle=shuffle, random_state=seed)\n",
    "    scores = []\n",
    "    for tr, te in kf.split(x):\n",
    "        res_tr = fit_fixed_lambda(x[tr], y[tr], lam, family, df, degree, spline_type)\n",
    "        # predict on test using fixed Œ≤ from train\n",
    "        Xs, S, _ = build_spline_basis(x[tr], spline_type, df, degree)\n",
    "        Xt  = np.hstack([np.ones((len(tr),1)), Xs])\n",
    "        # rebuild for test points using same basis constructor\n",
    "        Xs_te, _, _ = build_spline_basis(x[te], spline_type, df, degree)\n",
    "        Xt_te = np.hstack([np.ones((len(te),1)), Xs_te])\n",
    "\n",
    "        # We need Œ≤ from the training fit:\n",
    "        out_tr = fit_fixed_lambda(x[tr], y[tr], lam, family, df, degree, spline_type, return_internals=True)\n",
    "        beta = out_tr[\"beta\"]\n",
    "        yhat_te = Xt_te @ beta\n",
    "\n",
    "        if metric == \"rmse\":\n",
    "            s = float(np.sqrt(np.mean((y[te] - yhat_te)**2)))\n",
    "        elif metric == \"deviance\":\n",
    "            mu_te = yhat_te if family==\"gaussian\" else family_spec(family)[\"inv\"](Xt_te @ beta)\n",
    "            s = float(_glm_deviance(y[te], mu_te, family))\n",
    "        else:\n",
    "            raise ValueError(\"metric should be 'rmse' or 'deviance'\")\n",
    "        scores.append(s)\n",
    "\n",
    "    return {\"lam\": lam, \"K\": K, \"metric\": metric, \"scores\": scores,\n",
    "            \"mean\": float(np.mean(scores)), \"std\": float(np.std(scores))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8d7bc-2812-45b8-ae3c-c8c7adee3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"Northing\"].values.astype(float)\n",
    "y = data[\"Yield\"].values.astype(float)\n",
    "\n",
    "# Example: test Œª = 1\n",
    "diag = kfold_cv_fixed_lambda(x, y, lam=1.0, family=\"gaussian\", df=12, degree=3, spline_type=\"cr\", K=5)\n",
    "print(diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d346e-0bc4-4a1b-b769-81ea087f6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_grid = np.logspace(-3, 3, 15)\n",
    "results = []\n",
    "for lam in lam_grid:\n",
    "    cv = kfold_cv_fixed_lambda(x, y, lam=lam, family=\"gaussian\", df=12, degree=3, spline_type=\"cr\", K=5)\n",
    "    results.append((lam, cv[\"mean\"], cv[\"std\"]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "lams, means, stds = zip(*results)\n",
    "plt.semilogx(lams, means, marker='o')\n",
    "plt.fill_between(lams, np.array(means)-np.array(stds), np.array(means)+np.array(stds), alpha=0.2)\n",
    "plt.xlabel(\"Œª (fixed)\")\n",
    "plt.ylabel(\"Mean 5-fold RMSE\")\n",
    "plt.title(\"Cross-validated RMSE vs Œª\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921721a-b04e-4b48-8551-5838021e8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_grid = np.logspace(-3, 5, 30)\n",
    "edfs = []\n",
    "for lam in lam_grid:\n",
    "    res = fit_fixed_lambda(x, y, lam, return_internals=True)\n",
    "    edfs.append(res[\"edf\"])\n",
    "plt.semilogx(lam_grid, edfs, marker=\"o\")\n",
    "plt.xlabel(\"Œª\"); plt.ylabel(\"Effective df\")\n",
    "plt.title(\"edf(Œª) monotonicity check\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8900e-5ce1-4678-9c76-947c010c69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import r, conversion, default_converter, numpy2ri\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def rpy2_numpy_context():\n",
    "    with conversion.localconverter(default_converter + numpy2ri.converter):\n",
    "        yield\n",
    "\n",
    "r('suppressPackageStartupMessages(library(mgcv))')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660dcedc-6d50-408d-a0ea-3413bcd0de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_mgcv_fixed_lambda(x, y, lam=1.0, k=12, bs=\"cr\", family=\"gaussian\", plot=True):\n",
    "    \"\"\"\n",
    "    Compare Python IRLS GAM vs R mgcv::gam at a fixed lambda (sp=lam)\n",
    "    using your verified rpy2 connection.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(f\"Running mgcv::gam at Œª={lam}\")\n",
    "\n",
    "    with rpy2_numpy_context():\n",
    "        r.assign(\"x\", np.asarray(x))\n",
    "        r.assign(\"y\", np.asarray(y))\n",
    "        r.assign(\"lam\", float(lam))\n",
    "        r.assign(\"k\", int(k))\n",
    "        r.assign(\"bs\", bs)\n",
    "        r.assign(\"fam\", family)\n",
    "\n",
    "        r('''\n",
    "            suppressPackageStartupMessages(library(mgcv))\n",
    "            dat <- data.frame(x=x, y=y)\n",
    "            fit <- gam(y ~ s(x, k=k, bs=bs), data=dat, sp=lam, family=fam)\n",
    "            yhat <- fitted(fit)\n",
    "            edf  <- sum(fit$edf)\n",
    "        ''')\n",
    "\n",
    "        yhat_r = np.array(r(\"yhat\"))\n",
    "        edf_r = float(r(\"edf\")[0])\n",
    "\n",
    "    # --- Python-side fit (you already have your IRLS)\n",
    "    out_py = fit_fixed_lambda(x, y, lam=lam, family=family, df=k, degree=3,\n",
    "                              spline_type=bs, return_internals=True)\n",
    "    yhat_py = out_py[\"X\"] @ out_py[\"beta\"]\n",
    "    edf_py = out_py[\"edf\"]\n",
    "\n",
    "    # --- Compare ---\n",
    "    rmse = np.sqrt(np.mean((yhat_py - yhat_r)**2))\n",
    "    print(f\"‚úÖ RMSE between Python and mgcv fits: {rmse:.3e}\")\n",
    "    print(f\"EDF_Python = {edf_py:.3f}, EDF_mgcv = {edf_r:.3f}\")\n",
    "\n",
    "    # --- Plot overlay ---\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.scatter(x, y, s=20, color='gray', label='Observed')\n",
    "        plt.plot(x, yhat_py, 'r--', lw=2, label='Python IRLS GAM')\n",
    "        plt.plot(x, yhat_r, 'g-', lw=2, label='R mgcv GAM')\n",
    "        plt.title(f\"GAM Comparison at Œª={lam}\")\n",
    "        plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"edf_py\": edf_py,\n",
    "        \"edf_r\": edf_r,\n",
    "        \"yhat_py\": yhat_py,\n",
    "        \"yhat_r\": yhat_r\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b8ac5-0f3a-4447-8e59-7fd9b2994fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from your previous result object or dataset\n",
    "x = res[\"x\"] if \"x\" in res else data[\"Northing\"].values\n",
    "y = res[\"y\"] if \"y\" in res else data[\"Yield\"].values\n",
    "\n",
    "# Now call the mgcv comparison\n",
    "res_cmp = compare_with_mgcv_fixed_lambda(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    lam=1.0,\n",
    "    k=12,\n",
    "    bs=\"cr\",\n",
    "    family=\"gaussian\",\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1620f0-d8c8-47d2-87df-cea6027ec8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
